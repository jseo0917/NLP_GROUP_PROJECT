{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nahyun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nahyun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\nahyun\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gwpy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# !pip install rouge_score\n",
    "# !pip install py7zr\n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install rouge\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import csv\n",
    "import argparse\n",
    "import pickle\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.6221945137157\n",
      "201.90274314214463\n",
      "2848\n",
      "515\n"
     ]
    }
   ],
   "source": [
    "train_parsed = pd.read_csv('./Results_csv/twcs_train.csv')\n",
    "\n",
    "input_len = []\n",
    "target_len = []\n",
    "\n",
    "for i in range(len(train_parsed)):\n",
    "    dialog_len = len(train_parsed.iloc[i]['dialog'])\n",
    "    summary_len = len(train_parsed.iloc[i]['summary'])\n",
    "    input_len.append(dialog_len)\n",
    "    target_len.append(summary_len)\n",
    "\n",
    "print(sum(input_len)/len(input_len))\n",
    "print(sum(target_len)/len(target_len))\n",
    "\n",
    "print(max(input_len))\n",
    "print(max(target_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 620\n",
    "max_target = 202\n",
    "# batch_size = 100\n",
    "# model_name = \"philschmid/distilbart-cnn-12-6-samsum\"\n",
    "model_name = \"linydub/bart-large-samsum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "  #get all the dialogues  \n",
    "  data_to_process['dialog'] = data_to_process['dialog'].astype('string')\n",
    "  data_to_process['summary'] = data_to_process['summary'].astype('string')\n",
    "  list_summary = list(data_to_process['summary'])\n",
    "  inputs = [dialogue for dialogue in data_to_process['dialog']]\n",
    "  #tokenize the dialogues\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "  #tokenize the summaries\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(list_summary, max_length=max_target, padding='max_length', truncation=True)\n",
    "  #set labels\n",
    "  'id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'\n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "\n",
    "  #return the tokenized data\n",
    "  #input_ids, attention_mask and labels\n",
    "  results = []\n",
    "  for i in range (len(list(data_to_process['dialog']))):\n",
    "    dic = {'dialogue':list(data_to_process['dialog'])[i], 'summary':list(data_to_process['summary'])[i],'input_ids':model_inputs['input_ids'][i], 'attention_mask':model_inputs['attention_mask'][i], 'labels':model_inputs['labels'][i]}\n",
    "    results.append(dic)\n",
    "  return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahyun\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_parsed = pd.read_csv('./Results_csv/twcs_train.csv')\n",
    "valid_parsed = pd.read_csv('./Results_csv/twcs_val.csv')\n",
    "test_parsed = pd.read_csv('./Results_csv/twcs_test.csv')\n",
    "\n",
    "preprocessed_train_data = preprocess_data(train_parsed)\n",
    "preprocessed_valid_data = preprocess_data(valid_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue': '135060: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD\\nAppleSupport: @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\n135060: @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\\n',\n",
       " 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.',\n",
       " 'input_ids': [0,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  35,\n",
       "  407,\n",
       "  5063,\n",
       "  127,\n",
       "  2733,\n",
       "  3486,\n",
       "  127,\n",
       "  1257,\n",
       "  3075,\n",
       "  32,\n",
       "  5492,\n",
       "  127,\n",
       "  2402,\n",
       "  73,\n",
       "  30280,\n",
       "  6,\n",
       "  8,\n",
       "  1309,\n",
       "  630,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  11865,\n",
       "  1169,\n",
       "  1300,\n",
       "  5988,\n",
       "  13,\n",
       "  103,\n",
       "  1219,\n",
       "  4,\n",
       "  5053,\n",
       "  2956,\n",
       "  116,\n",
       "  1205,\n",
       "  640,\n",
       "  90,\n",
       "  4,\n",
       "  876,\n",
       "  73,\n",
       "  119,\n",
       "  466,\n",
       "  5174,\n",
       "  1864,\n",
       "  428,\n",
       "  330,\n",
       "  2543,\n",
       "  495,\n",
       "  50118,\n",
       "  20770,\n",
       "  38873,\n",
       "  35,\n",
       "  787,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  2780,\n",
       "  17,\n",
       "  27,\n",
       "  29,\n",
       "  4830,\n",
       "  42,\n",
       "  561,\n",
       "  4,\n",
       "  598,\n",
       "  386,\n",
       "  6,\n",
       "  64,\n",
       "  47,\n",
       "  1137,\n",
       "  201,\n",
       "  5,\n",
       "  2257,\n",
       "  7952,\n",
       "  110,\n",
       "  2733,\n",
       "  8,\n",
       "  1257,\n",
       "  3075,\n",
       "  32,\n",
       "  878,\n",
       "  855,\n",
       "  116,\n",
       "  50118,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  35,\n",
       "  787,\n",
       "  20770,\n",
       "  38873,\n",
       "  1308,\n",
       "  2733,\n",
       "  16,\n",
       "  15,\n",
       "  365,\n",
       "  4,\n",
       "  134,\n",
       "  4,\n",
       "  176,\n",
       "  6,\n",
       "  8,\n",
       "  127,\n",
       "  1183,\n",
       "  16,\n",
       "  15,\n",
       "  204,\n",
       "  4,\n",
       "  134,\n",
       "  4,\n",
       "  50118,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [0,\n",
       "  44799,\n",
       "  17730,\n",
       "  7651,\n",
       "  59,\n",
       "  39,\n",
       "  38,\n",
       "  17283,\n",
       "  8,\n",
       "  1257,\n",
       "  1183,\n",
       "  61,\n",
       "  16,\n",
       "  45,\n",
       "  2018,\n",
       "  39,\n",
       "  143,\n",
       "  2402,\n",
       "  73,\n",
       "  30280,\n",
       "  8,\n",
       "  474,\n",
       "  1713,\n",
       "  4,\n",
       "  18497,\n",
       "  16,\n",
       "  1996,\n",
       "  7,\n",
       "  517,\n",
       "  7,\n",
       "  18695,\n",
       "  8,\n",
       "  356,\n",
       "  88,\n",
       "  24,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue': '135060: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD\\nAppleSupport: @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\n135060: @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\\n',\n",
       " 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.',\n",
       " 'input_ids': [0,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  35,\n",
       "  407,\n",
       "  5063,\n",
       "  127,\n",
       "  2733,\n",
       "  3486,\n",
       "  127,\n",
       "  1257,\n",
       "  3075,\n",
       "  32,\n",
       "  5492,\n",
       "  127,\n",
       "  2402,\n",
       "  73,\n",
       "  30280,\n",
       "  6,\n",
       "  8,\n",
       "  1309,\n",
       "  630,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  11865,\n",
       "  1169,\n",
       "  1300,\n",
       "  5988,\n",
       "  13,\n",
       "  103,\n",
       "  1219,\n",
       "  4,\n",
       "  5053,\n",
       "  2956,\n",
       "  116,\n",
       "  1205,\n",
       "  640,\n",
       "  90,\n",
       "  4,\n",
       "  876,\n",
       "  73,\n",
       "  119,\n",
       "  466,\n",
       "  5174,\n",
       "  1864,\n",
       "  428,\n",
       "  330,\n",
       "  2543,\n",
       "  495,\n",
       "  50118,\n",
       "  20770,\n",
       "  38873,\n",
       "  35,\n",
       "  787,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  2780,\n",
       "  17,\n",
       "  27,\n",
       "  29,\n",
       "  4830,\n",
       "  42,\n",
       "  561,\n",
       "  4,\n",
       "  598,\n",
       "  386,\n",
       "  6,\n",
       "  64,\n",
       "  47,\n",
       "  1137,\n",
       "  201,\n",
       "  5,\n",
       "  2257,\n",
       "  7952,\n",
       "  110,\n",
       "  2733,\n",
       "  8,\n",
       "  1257,\n",
       "  3075,\n",
       "  32,\n",
       "  878,\n",
       "  855,\n",
       "  116,\n",
       "  50118,\n",
       "  1558,\n",
       "  1096,\n",
       "  2466,\n",
       "  35,\n",
       "  787,\n",
       "  20770,\n",
       "  38873,\n",
       "  1308,\n",
       "  2733,\n",
       "  16,\n",
       "  15,\n",
       "  365,\n",
       "  4,\n",
       "  134,\n",
       "  4,\n",
       "  176,\n",
       "  6,\n",
       "  8,\n",
       "  127,\n",
       "  1183,\n",
       "  16,\n",
       "  15,\n",
       "  204,\n",
       "  4,\n",
       "  134,\n",
       "  4,\n",
       "  50118,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [0,\n",
       "  44799,\n",
       "  17730,\n",
       "  7651,\n",
       "  59,\n",
       "  39,\n",
       "  38,\n",
       "  17283,\n",
       "  8,\n",
       "  1257,\n",
       "  1183,\n",
       "  61,\n",
       "  16,\n",
       "  45,\n",
       "  2018,\n",
       "  39,\n",
       "  143,\n",
       "  2402,\n",
       "  73,\n",
       "  30280,\n",
       "  8,\n",
       "  474,\n",
       "  1713,\n",
       "  4,\n",
       "  18497,\n",
       "  16,\n",
       "  1996,\n",
       "  7,\n",
       "  517,\n",
       "  7,\n",
       "  18695,\n",
       "  8,\n",
       "  356,\n",
       "  88,\n",
       "  24,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessd_test_data = preprocess_data(test_parsed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rouge metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahyun\\AppData\\Local\\Temp\\ipykernel_3908\\3065557357.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('rouge')\n"
     ]
    }
   ],
   "source": [
    "# model_name=\"philschmid/distilbart-cnn-12-6-samsum\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "metric = load_metric('rouge')\n",
    "collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "def compute_rouge(pred):\n",
    "  predictions, labels = pred\n",
    "  #decode the predictions\n",
    "  decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  #decode labels\n",
    "  decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  #compute results\n",
    "  res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n",
    "  #get %\n",
    "  res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n",
    "\n",
    "  pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "  res['gen_len'] = np.mean(pred_lens)\n",
    "\n",
    "  return {k: round(v, 4) for k, v in res.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.integrations import TrainerCallback, is_tensorboard_available\n",
    "\n",
    "def custom_rewrite_logs(d, mode):\n",
    "    new_d = {}\n",
    "    eval_prefix = \"eval_\"\n",
    "    eval_prefix_len = len(eval_prefix)\n",
    "    test_prefix = \"test_\"\n",
    "    test_prefix_len = len(test_prefix)\n",
    "    for k, v in d.items():\n",
    "        if mode == 'eval' and k.startswith(eval_prefix):\n",
    "            if k[eval_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[eval_prefix_len:]] = v\n",
    "        elif mode == 'test' and k.startswith(test_prefix):\n",
    "            if k[test_prefix_len:] == 'loss':\n",
    "                new_d[\"combined/\" + k[test_prefix_len:]] = v\n",
    "        elif mode == 'train':\n",
    "            if k == 'loss':\n",
    "                new_d[\"combined/\" + k] = v\n",
    "    return new_d\n",
    "\n",
    "\n",
    "class CombinedTensorBoardCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A [`TrainerCallback`] that sends the logs to [TensorBoard](https://www.tensorflow.org/tensorboard).\n",
    "    Args:\n",
    "        tb_writer (`SummaryWriter`, *optional*):\n",
    "            The writer to use. Will instantiate one if not set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tb_writers=None):\n",
    "        has_tensorboard = is_tensorboard_available()\n",
    "        if not has_tensorboard:\n",
    "            raise RuntimeError(\n",
    "                \"TensorBoardCallback requires tensorboard to be installed. Either update your PyTorch version or\"\n",
    "                \" install tensorboardX.\"\n",
    "            )\n",
    "        if has_tensorboard:\n",
    "            try:\n",
    "                from torch.utils.tensorboard import SummaryWriter  # noqa: F401\n",
    "\n",
    "                self._SummaryWriter = SummaryWriter\n",
    "            except ImportError:\n",
    "                try:\n",
    "                    from tensorboardX import SummaryWriter\n",
    "\n",
    "                    self._SummaryWriter = SummaryWriter\n",
    "                except ImportError:\n",
    "                    self._SummaryWriter = None\n",
    "        else:\n",
    "            self._SummaryWriter = None\n",
    "        self.tb_writers = tb_writers\n",
    "\n",
    "    def _init_summary_writer(self, args, log_dir=None):\n",
    "        log_dir = log_dir or args.logging_dir\n",
    "        if self._SummaryWriter is not None:\n",
    "            self.tb_writers = dict(train=self._SummaryWriter(log_dir=os.path.join(log_dir, 'train')),\n",
    "                                   eval=self._SummaryWriter(log_dir=os.path.join(log_dir, 'eval')))\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        log_dir = None\n",
    "\n",
    "        if state.is_hyper_param_search:\n",
    "            trial_name = state.trial_name\n",
    "            if trial_name is not None:\n",
    "                log_dir = os.path.join(args.logging_dir, trial_name)\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args, log_dir)\n",
    "\n",
    "        for k, tbw in self.tb_writers.items():\n",
    "            tbw.add_text(\"args\", args.to_json_string())\n",
    "            if \"model\" in kwargs:\n",
    "                model = kwargs[\"model\"]\n",
    "                if hasattr(model, \"config\") and model.config is not None:\n",
    "                    model_config_json = model.config.to_json_string()\n",
    "                    tbw.add_text(\"model_config\", model_config_json)\n",
    "            # Version of TensorBoard coming from tensorboardX does not have this method.\n",
    "            if hasattr(tbw, \"add_hparams\"):\n",
    "                tbw.add_hparams(args.to_sanitized_dict(), metric_dict={})\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not state.is_world_process_zero:\n",
    "            return\n",
    "\n",
    "        if self.tb_writers is None:\n",
    "            self._init_summary_writer(args)\n",
    "\n",
    "        for tbk, tbw in self.tb_writers.items():\n",
    "            logs_new = custom_rewrite_logs(logs, mode=tbk)\n",
    "            for k, v in logs_new.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    tbw.add_scalar(k, v, state.global_step)\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"Trainer is attempting to log a value of \"\n",
    "                        f'\"{v}\" of type {type(v)} for key \"{k}\" as a scalar. '\n",
    "                        \"This invocation of Tensorboard's writer.add_scalar() \"\n",
    "                        \"is incorrect so we dropped this attribute.\"\n",
    "                    )\n",
    "            tbw.flush()\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        for tbw in self.tb_writers.values():\n",
    "            tbw.close()\n",
    "        self.tb_writers = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience= 3, \n",
    "                                    early_stopping_threshold= 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './training-log/bart-5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "output_dir = './training-log/bart-5/'\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy='steps',\n",
    "    learning_rate=2e-7,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.0001,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=20,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps=3,\n",
    "    fp16=True,\n",
    "    overwrite_output_dir= True,\n",
    "    load_best_model_at_end = True,\n",
    "    save_strategy='steps',\n",
    "    report_to=\"wandb\",\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset=preprocessed_train_data,\n",
    "    eval_dataset=preprocessed_valid_data,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_rouge,\n",
    "    callbacks=[CombinedTensorBoardCallback, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahyun\\anaconda3\\envs\\torch\\lib\\site-packages\\accelerate\\memory_utils.py:23: FutureWarning: memory_utils has been reorganized to utils.memory. Import `find_executable_batchsize` from the main `__init__`: `from accelerate import find_executable_batch_size` to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahyun\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2406\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 8020\n",
      "  Number of trainable parameters = 406291456\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnahyunkwon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\nahyun\\Projects\\nlp_project\\wandb\\run-20221129_130321-gutnbh7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nahyunkwon/huggingface/runs/gutnbh7f\" target=\"_blank\">./training-log/bart-5/</a></strong> to <a href=\"https://wandb.ai/nahyunkwon/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8020' max='8020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8020/8020 1:31:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>10.690200</td>\n",
       "      <td>8.474370</td>\n",
       "      <td>38.171500</td>\n",
       "      <td>17.317500</td>\n",
       "      <td>30.895700</td>\n",
       "      <td>30.833100</td>\n",
       "      <td>41.559600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.231700</td>\n",
       "      <td>6.019929</td>\n",
       "      <td>43.227400</td>\n",
       "      <td>19.607700</td>\n",
       "      <td>35.690800</td>\n",
       "      <td>35.645600</td>\n",
       "      <td>46.868500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.130100</td>\n",
       "      <td>5.577246</td>\n",
       "      <td>46.573600</td>\n",
       "      <td>22.816200</td>\n",
       "      <td>39.072300</td>\n",
       "      <td>38.983700</td>\n",
       "      <td>50.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.781500</td>\n",
       "      <td>5.365711</td>\n",
       "      <td>48.337200</td>\n",
       "      <td>24.415000</td>\n",
       "      <td>40.974100</td>\n",
       "      <td>40.874100</td>\n",
       "      <td>50.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.568400</td>\n",
       "      <td>5.227052</td>\n",
       "      <td>48.829300</td>\n",
       "      <td>24.753500</td>\n",
       "      <td>41.393900</td>\n",
       "      <td>41.325900</td>\n",
       "      <td>49.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.427000</td>\n",
       "      <td>5.119960</td>\n",
       "      <td>49.573300</td>\n",
       "      <td>25.451200</td>\n",
       "      <td>42.293400</td>\n",
       "      <td>42.203300</td>\n",
       "      <td>49.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.287400</td>\n",
       "      <td>5.024884</td>\n",
       "      <td>49.882700</td>\n",
       "      <td>25.867100</td>\n",
       "      <td>42.720900</td>\n",
       "      <td>42.677900</td>\n",
       "      <td>48.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.184300</td>\n",
       "      <td>4.942989</td>\n",
       "      <td>50.002700</td>\n",
       "      <td>25.947500</td>\n",
       "      <td>42.879100</td>\n",
       "      <td>42.835100</td>\n",
       "      <td>48.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.099800</td>\n",
       "      <td>4.872396</td>\n",
       "      <td>49.993700</td>\n",
       "      <td>26.072300</td>\n",
       "      <td>42.974300</td>\n",
       "      <td>42.903100</td>\n",
       "      <td>48.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.012500</td>\n",
       "      <td>4.809988</td>\n",
       "      <td>49.871100</td>\n",
       "      <td>26.119200</td>\n",
       "      <td>42.911500</td>\n",
       "      <td>42.869400</td>\n",
       "      <td>47.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.958500</td>\n",
       "      <td>4.757683</td>\n",
       "      <td>50.250200</td>\n",
       "      <td>26.493200</td>\n",
       "      <td>43.295100</td>\n",
       "      <td>43.240600</td>\n",
       "      <td>47.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.894900</td>\n",
       "      <td>4.715267</td>\n",
       "      <td>50.348200</td>\n",
       "      <td>26.860900</td>\n",
       "      <td>43.613700</td>\n",
       "      <td>43.569300</td>\n",
       "      <td>47.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.850600</td>\n",
       "      <td>4.681957</td>\n",
       "      <td>50.312900</td>\n",
       "      <td>26.801500</td>\n",
       "      <td>43.496300</td>\n",
       "      <td>43.460500</td>\n",
       "      <td>47.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.820500</td>\n",
       "      <td>4.658543</td>\n",
       "      <td>50.202900</td>\n",
       "      <td>26.631100</td>\n",
       "      <td>43.330900</td>\n",
       "      <td>43.272500</td>\n",
       "      <td>47.388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.801800</td>\n",
       "      <td>4.643913</td>\n",
       "      <td>50.120400</td>\n",
       "      <td>26.515700</td>\n",
       "      <td>43.169500</td>\n",
       "      <td>43.112000</td>\n",
       "      <td>47.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.785400</td>\n",
       "      <td>4.638604</td>\n",
       "      <td>50.196300</td>\n",
       "      <td>26.516900</td>\n",
       "      <td>43.158200</td>\n",
       "      <td>43.096900</td>\n",
       "      <td>47.565700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-1000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-1000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-1000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-1500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-1500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-1500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-2000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-2000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-2000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-2500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-2500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-2500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-3000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-3000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-3000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-3500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-3500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-3500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-4000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-4000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-4000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-4500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-4500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-4500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-3500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-5000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-5000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-5000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-4000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-5500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-5500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-5500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-6000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-6000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-6000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-6500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-6500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-6500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-7000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-7000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-7000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-6000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-7500\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-7500\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-7500\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 327\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, dialogue. If summary, dialogue are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./training-log/bart-5/checkpoint-8000\n",
      "Configuration saved in ./training-log/bart-5/checkpoint-8000\\config.json\n",
      "Model weights saved in ./training-log/bart-5/checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./training-log/bart-5/checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in ./training-log/bart-5/checkpoint-8000\\special_tokens_map.json\n",
      "Deleting older checkpoint [training-log\\bart-5\\checkpoint-7000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./training-log/bart-5/checkpoint-8000 (score: 4.638604164123535).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8020, training_loss=5.655690958493963, metrics={'train_runtime': 5468.4971, 'train_samples_per_second': 8.799, 'train_steps_per_second': 1.467, 'total_flos': 6.31389311926272e+16, 'train_loss': 5.655690958493963, 'epoch': 20.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### %%wandb\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models/bart-5/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"./models/bart-5/\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./models/bart-5/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at ./models/bart-5/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "output_dir='./models/bart-5'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('./models/bart-5/')\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy='steps',\n",
    "    learning_rate=2e-7,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.0001,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=20,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps=3,\n",
    "    fp16=True,\n",
    "    overwrite_output_dir= True,\n",
    "    load_best_model_at_end = True,\n",
    "    save_strategy='steps',\n",
    "    report_to=\"wandb\",\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset=preprocessed_train_data,\n",
    "    eval_dataset=preprocessed_valid_data,\n",
    "#     data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_rouge,\n",
    "    callbacks=[CombinedTensorBoardCallback, early_stopping]\n",
    ")\n",
    "\n",
    "##### %%wandb\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model('./models/bart-5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting using tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir training-log/bart/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_sum = []\n",
    "for test_dialog in test_parsed['dialog']:\n",
    "  model_inputs = tokenizer(test_dialog,  max_length=max_input, padding='max_length', truncation=True)\n",
    "  raw_pred, _, _ = trainer.predict([model_inputs])\n",
    "  predicted_sum.append(tokenizer.decode(raw_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for summary in predicted_sum:\n",
    "  summary= summary.replace('</s>', '')\n",
    "  summary= summary.replace('<s>', '')\n",
    "  summary= summary.replace('<pad>', '')\n",
    "  cleaned_data.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parsed['finetuned_predicted'] = cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.4738073266877376,\n",
       "  'p': 0.43975257088964653,\n",
       "  'f': 0.4461211256664116},\n",
       " 'rouge-2': {'r': 0.2210733286740097,\n",
       "  'p': 0.21420516146898858,\n",
       "  'f': 0.21063012684483115},\n",
       " 'rouge-l': {'r': 0.4443579233029028,\n",
       "  'p': 0.41197299731042186,\n",
       "  'f': 0.41798705969027306}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = list(test_parsed['summary'])\n",
    "\n",
    "rouge = Rouge()\n",
    "rouge.get_scores(list(test_parsed['finetuned_predicted']), summaries, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_parsed.to_csv(\"predicted_with_bart_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_Rouge_Scores(X, Y):  \n",
    "  rouge = Rouge()\n",
    "  return rouge.get_scores(X, Y)\n",
    "\n",
    "def get_rouge1_rouge2_scores_for_bxplot(test_parsed):\n",
    "  Rouge_1_f1scores_list = []\n",
    "  Rouge_2_f1scores_list = []\n",
    "  Rouge_1_precision_list = []\n",
    "  Rouge_2_precision_list = []\n",
    "  Rouge_1_recall_list = []\n",
    "  Rouge_2_recall_list = []\n",
    "  for i in range(len(test_parsed)):\n",
    "    X = test_parsed['summary'][i]\n",
    "    Y = test_parsed['finetuned_predicted'][i]\n",
    "    get_rouge_scores = generation_Rouge_Scores(X,Y)\n",
    "    Rouge_1_f1scores = get_rouge_scores[0]['rouge-1']['f']\n",
    "    Rouge_2_f1scores = get_rouge_scores[0]['rouge-2']['f']\n",
    "\n",
    "    Rouge_1_f1scores_list.append(Rouge_1_f1scores)\n",
    "    Rouge_2_f1scores_list.append(Rouge_2_f1scores)\n",
    "\n",
    "    Rouge_1_precision = get_rouge_scores[0]['rouge-1']['p']\n",
    "    Rouge_2_precision = get_rouge_scores[0]['rouge-2']['p']\n",
    "\n",
    "    Rouge_1_precision_list.append(Rouge_1_precision)\n",
    "    Rouge_2_precision_list.append(Rouge_2_precision)\n",
    "\n",
    "    Rouge_1_recall = get_rouge_scores[0]['rouge-1']['r']\n",
    "    Rouge_2_recall = get_rouge_scores[0]['rouge-2']['r']\n",
    "\n",
    "    Rouge_1_recall_list.append(Rouge_1_recall)\n",
    "    Rouge_2_recall_list.append(Rouge_2_recall)\n",
    "  return Rouge_1_f1scores_list, Rouge_2_f1scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max for Rouge_1 f1 scores    :  0.8421052581717452\n",
      "Min for Rouge_1 f1 scores    :  0.09999999505000023\n",
      "Mean for Rouge_1 f1 scores   :  0.4461211256664115\n",
      "Median for Rouge_1 f1 scores :  0.4363636316429752\n"
     ]
    }
   ],
   "source": [
    "Rouge_1_f1scores_finetuned_CNN, Rouge_2_f1scores_finetuned_CNN = get_rouge1_rouge2_scores_for_bxplot(test_parsed)\n",
    "print(\"Max for Rouge_1 f1 scores    : \", np.max(Rouge_1_f1scores_finetuned_CNN))\n",
    "print(\"Min for Rouge_1 f1 scores    : \", np.min(Rouge_1_f1scores_finetuned_CNN))\n",
    "print(\"Mean for Rouge_1 f1 scores   : \", np.mean(Rouge_1_f1scores_finetuned_CNN))\n",
    "print(\"Median for Rouge_1 f1 scores : \", np.median(Rouge_1_f1scores_finetuned_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Rouge 1 f1 scores for bart model'}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.title(\"Rouge 1 f1 scores for bart model\")\n",
    "sns.boxplot(x=Rouge_1_f1scores_finetuned_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max for Rouge_2 f1 scores    :  0.679999995288\n",
      "Min for Rouge_2 f1 scores    :  0.0\n",
      "Mean for Rouge_2 f1 scores   :  0.21063012684483126\n",
      "Median for Rouge_2 f1 scores :  0.1797752761267518\n"
     ]
    }
   ],
   "source": [
    "print(\"Max for Rouge_2 f1 scores    : \", np.max(Rouge_2_f1scores_finetuned_CNN))\n",
    "print(\"Min for Rouge_2 f1 scores    : \", np.min(Rouge_2_f1scores_finetuned_CNN))\n",
    "print(\"Mean for Rouge_2 f1 scores   : \", np.mean(Rouge_2_f1scores_finetuned_CNN))\n",
    "print(\"Median for Rouge_2 f1 scores : \", np.median(Rouge_2_f1scores_finetuned_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Rouge 2 f1 scores for bart model'}>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.title(\"Rouge 2 f1 scores for bart model\")\n",
    "sns.boxplot(x=Rouge_2_f1scores_finetuned_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0806569fb08f6281673bd527a613de0eff307c0935f5ba0f859440fd02939511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
